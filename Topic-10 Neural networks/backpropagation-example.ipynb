{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "Here is a quick representation of the backpropagation algorithm for the simple two node network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Steps to backpropagation\n",
    "\n",
    "We outlined 4 steps to perform backpropagation,\n",
    "\n",
    "   1. Choose random initial weights.\n",
    "   2. Fix input at desired value, and calculate output.\n",
    "   3. Update the weights.\n",
    "   4. Repeat steps 2 & 3 many times.\n",
    "\n",
    "Let's now implement these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's generate some data using known values for the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))     # Define the sigmoid anonymous function.\n",
    "\n",
    "def feedforward(w, s0):         # Define feedforward solution.\n",
    "    x1 = w[0]*s0                # ... activity of first neuron,\n",
    "    s1 = sigmoid(x1)            # ... output of first neuron,\n",
    "    x2 = w[1]*s1                # ... activity of second neuron,\n",
    "    s2 = sigmoid(x2)            # ... output of second neuron,\n",
    "    out= w[2]*s2                # Output of neural network.\n",
    "    return out,s1,s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data\n",
    "w_true  = [1,-2,3]                      # Set true weights\n",
    "out_true,in_true = [], []\n",
    "K = 100000\n",
    "for k in np.arange(K):                  # Generate K samples, \n",
    "    s0 = np.random.randn(1)             # ... with random input,\n",
    "    out,s1,s2= feedforward(w_true, s0)  # ... compute the output,\n",
    "    out_true = np.append(out_true, out) # ... and save it.\n",
    "    in_true  = np.append(in_true,  s0)  # ... also save the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the list of inputs (s0) and outputs (out).\n",
    "These are the data we'll use to train the neural network through back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.transpose([in_true, out_true]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's train the neural network with these (inputs,outputs) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w     = [1,1,1]                  # Choose initial values for the weights.\n",
    "alpha = 0.05                    # Set the learning constant.\n",
    "\n",
    "results = np.zeros([K,4])        # Define a variable to hold the results of each iteration.    \n",
    "\n",
    "for k in np.arange(K):\n",
    "    s0     = in_true[k]          # Define the input,\n",
    "    target = out_true[k]         # ... and the target output.\n",
    "    \n",
    "    #Step 2. Calculate feedforward solution to get output.\n",
    "    out,s1,s2    = feedforward(w, s0)\n",
    "    \n",
    "    #Step 3. Update the weights.\n",
    "    w[2] = w[2] - alpha*(out-target)*s2\n",
    "    w[1] = w[1] - alpha*(out-target)*(w[2]*s2*(1-s2)*s1)\n",
    "    w[0] = w[0] - alpha*(out-target)*(w[2]*s2*(1-s2)*w[1])*(s1*(1-s1)*s0)\n",
    "    \n",
    "    # Save the results of this step. --------------------------------------\n",
    "    results[k,:] = [w[0],w[1],w[2],  out]\n",
    "    # Here we save the 3 weights, the neural network output.\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(results[:,2], label='w2')\n",
    "plt.plot(results[:,1], label='w1')\n",
    "plt.plot(results[:,0], label='w0')\n",
    "plt.plot(results[:,3]-target, label='error')\n",
    "plt.legend()                       #Include a legend,\n",
    "plt.xlabel('Iteration number');    #... and axis label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the true and NN weights\n",
    "print(w_true)\n",
    "print(results[-1,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the NN\n",
    "s0 = 0.5\n",
    "print('True weights output:', feedforward(w_true, s0)[0])\n",
    "print('  NN weights output:', feedforward(w,      s0)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
